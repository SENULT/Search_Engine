"""
INVERTED INDEX BUILDER FOR SEARCH ENGINE

XÃ¢y dá»±ng Inverted Index tá»« preprocessed text vÃ  lÆ°u vÃ o database/files.

Features:
1. Build Inverted Index from preprocessed documents
2. Calculate TF-IDF scores
3. Store index in MongoDB and JSON files
4. Support incremental indexing
5. Query optimization
"""

import os
import json
import math
from collections import defaultdict, Counter
from datetime import datetime
from typing import Dict, List, Tuple, Set
from tqdm import tqdm
import pickle

# MongoDB
from pymongo import MongoClient
import certifi
from dotenv import load_dotenv

# Import tá»« text processing
import sys
sys.path.append(os.path.dirname(__file__))

load_dotenv()


class InvertedIndex:
    """
    Inverted Index vá»›i TF-IDF scoring
    
    Structure:
    {
        'term1': {
            'df': 10,  # document frequency
            'postings': {
                'doc_id1': {'tf': 5, 'positions': [1, 5, 10, 15, 20]},
                'doc_id2': {'tf': 3, 'positions': [2, 8, 15]},
                ...
            }
        },
        'term2': {...}
    }
    """
    
    def __init__(self):
        self.index = defaultdict(lambda: {'df': 0, 'postings': {}})
        self.doc_lengths = {}  # {doc_id: length}
        self.total_docs = 0
        self.avg_doc_length = 0
        self.vocabulary = set()
        
    def add_document(self, doc_id: str, tokens: List[str], store_positions: bool = True):
        """
        ThÃªm document vÃ o inverted index
        
        Args:
            doc_id: ID cá»§a document
            tokens: List cÃ¡c tokens Ä‘Ã£ preprocessing
            store_positions: CÃ³ lÆ°u vá»‹ trÃ­ cá»§a term khÃ´ng
        """
        # TÃ­nh term frequency vÃ  positions
        term_positions = defaultdict(list)
        
        for position, term in enumerate(tokens):
            term_positions[term].append(position)
        
        # Cáº­p nháº­t index
        for term, positions in term_positions.items():
            tf = len(positions)
            
            # Náº¿u term chÆ°a xuáº¥t hiá»‡n trong document nÃ y
            if doc_id not in self.index[term]['postings']:
                self.index[term]['df'] += 1  # TÄƒng document frequency
            
            # LÆ°u posting
            self.index[term]['postings'][doc_id] = {
                'tf': tf,
                'positions': positions if store_positions else []
            }
            
            self.vocabulary.add(term)
        
        # LÆ°u document length
        self.doc_lengths[doc_id] = len(tokens)
        self.total_docs += 1
        
    def calculate_idf(self, term: str) -> float:
        """
        TÃ­nh IDF (Inverse Document Frequency)
        IDF = log(N / df)
        """
        df = self.index[term]['df']
        if df == 0:
            return 0
        return math.log(self.total_docs / df)
    
    def calculate_tf_idf(self, term: str, doc_id: str) -> float:
        """
        TÃ­nh TF-IDF score
        TF-IDF = TF * IDF
        """
        if term not in self.index or doc_id not in self.index[term]['postings']:
            return 0
        
        tf = self.index[term]['postings'][doc_id]['tf']
        idf = self.calculate_idf(term)
        
        return tf * idf
    
    def calculate_bm25(self, term: str, doc_id: str, k1: float = 1.5, b: float = 0.75) -> float:
        """
        TÃ­nh BM25 score (cáº£i tiáº¿n cá»§a TF-IDF)
        
        BM25 = IDF * (tf * (k1 + 1)) / (tf + k1 * (1 - b + b * (doc_len / avg_doc_len)))
        """
        if term not in self.index or doc_id not in self.index[term]['postings']:
            return 0
        
        tf = self.index[term]['postings'][doc_id]['tf']
        idf = self.calculate_idf(term)
        doc_len = self.doc_lengths.get(doc_id, 0)
        
        if self.avg_doc_length == 0:
            self.avg_doc_length = sum(self.doc_lengths.values()) / len(self.doc_lengths) if self.doc_lengths else 1
        
        numerator = tf * (k1 + 1)
        denominator = tf + k1 * (1 - b + b * (doc_len / self.avg_doc_length))
        
        return idf * (numerator / denominator)
    
    def get_postings(self, term: str) -> Dict:
        """Láº¥y postings list cá»§a má»™t term"""
        return self.index.get(term, {'df': 0, 'postings': {}})
    
    def search(self, query_terms: List[str], method: str = 'bm25', top_k: int = 10) -> List[Tuple[str, float]]:
        """
        TÃ¬m kiáº¿m documents liÃªn quan Ä‘áº¿n query
        
        Args:
            query_terms: List cÃ¡c terms trong query (Ä‘Ã£ preprocessing)
            method: 'tfidf' hoáº·c 'bm25'
            top_k: Sá»‘ lÆ°á»£ng káº¿t quáº£ tráº£ vá»
            
        Returns:
            List[(doc_id, score)] sorted by score descending
        """
        # TÃ­nh score cho tá»«ng document
        doc_scores = defaultdict(float)
        
        for term in query_terms:
            if term not in self.index:
                continue
            
            postings = self.index[term]['postings']
            
            for doc_id in postings.keys():
                if method == 'bm25':
                    score = self.calculate_bm25(term, doc_id)
                else:  # tfidf
                    score = self.calculate_tf_idf(term, doc_id)
                
                doc_scores[doc_id] += score
        
        # Sáº¯p xáº¿p theo score
        sorted_docs = sorted(doc_scores.items(), key=lambda x: x[1], reverse=True)
        
        return sorted_docs[:top_k]
    
    def get_statistics(self) -> Dict:
        """Láº¥y thá»‘ng kÃª vá» index"""
        return {
            'total_documents': self.total_docs,
            'vocabulary_size': len(self.vocabulary),
            'avg_doc_length': self.avg_doc_length if self.avg_doc_length > 0 else sum(self.doc_lengths.values()) / len(self.doc_lengths) if self.doc_lengths else 0,
            'total_postings': sum(len(term_data['postings']) for term_data in self.index.values()),
            'index_size_terms': len(self.index)
        }
    
    def to_dict(self) -> Dict:
        """Convert index sang dictionary Ä‘á»ƒ lÆ°u file"""
        return {
            'index': dict(self.index),
            'doc_lengths': self.doc_lengths,
            'total_docs': self.total_docs,
            'avg_doc_length': self.avg_doc_length,
            'vocabulary': list(self.vocabulary)
        }
    
    @classmethod
    def from_dict(cls, data: Dict):
        """Load index tá»« dictionary"""
        inv_index = cls()
        inv_index.index = defaultdict(lambda: {'df': 0, 'postings': {}}, data['index'])
        inv_index.doc_lengths = data['doc_lengths']
        inv_index.total_docs = data['total_docs']
        inv_index.avg_doc_length = data['avg_doc_length']
        inv_index.vocabulary = set(data['vocabulary'])
        return inv_index


class IndexBuilder:
    """
    Builder Ä‘á»ƒ xÃ¢y dá»±ng vÃ  lÆ°u Inverted Index
    """
    
    def __init__(self, mongo_uri: str = None, db_name: str = "vnexpress_db"):
        self.mongo_uri = mongo_uri or os.getenv("MONGO_URI")
        self.db_name = db_name
        self.client = None
        self.db = None
        self.inverted_index = InvertedIndex()
        
    def connect_database(self):
        """Káº¿t ná»‘i MongoDB"""
        try:
            self.client = MongoClient(self.mongo_uri, tls=True, tlsCAFile=certifi.where())
            self.db = self.client[self.db_name]
            print(f"âœ“ ÄÃ£ káº¿t ná»‘i database: {self.db_name}")
            return True
        except Exception as e:
            print(f"âœ— Lá»—i káº¿t ná»‘i database: {e}")
            return False
    
    def build_index_from_collection(self, collection_name: str, token_field: str = 'filtered_tokens', limit: int = None):
        """
        XÃ¢y dá»±ng index tá»« MongoDB collection
        
        Args:
            collection_name: TÃªn collection chá»©a preprocessed data
            token_field: Field chá»©a tokens (filtered_tokens hoáº·c stemmed_tokens)
            limit: Giá»›i háº¡n sá»‘ documents (None = all)
        """
        if not self.db:
            if not self.connect_database():
                return False
        
        collection = self.db[collection_name]
        
        # Äáº¿m documents
        total_docs = collection.count_documents({})
        if limit:
            total_docs = min(total_docs, limit)
        
        print(f"\nğŸ”¨ Báº®T Äáº¦U XÃ‚Y Dá»°NG INVERTED INDEX")
        print(f"Collection: {collection_name}")
        print(f"Total documents: {total_docs}")
        print("="*80)
        
        # Láº¥y documents
        query = collection.find().limit(limit) if limit else collection.find()
        
        processed_count = 0
        error_count = 0
        
        for doc in tqdm(query, desc="Building index", total=total_docs):
            try:
                doc_id = str(doc.get('_id', ''))
                tokens = doc.get(token_field, [])
                
                if not tokens:
                    # Náº¿u khÃ´ng cÃ³ filtered_tokens, thá»­ láº¥y tokens
                    tokens = doc.get('tokens', [])
                
                if tokens:
                    self.inverted_index.add_document(doc_id, tokens, store_positions=True)
                    processed_count += 1
                    
            except Exception as e:
                error_count += 1
                print(f"\nLá»—i xá»­ lÃ½ document {doc.get('_id', 'unknown')}: {e}")
        
        print(f"\nâœ“ HoÃ n thÃ nh!")
        print(f"  - Processed: {processed_count}")
        print(f"  - Errors: {error_count}")
        
        # In thá»‘ng kÃª
        self.print_statistics()
        
        return True
    
    def build_index_from_json_files(self, json_files: List[str], token_field: str = 'filtered_tokens'):
        """
        XÃ¢y dá»±ng index tá»« cÃ¡c JSON files (preprocessed data)
        
        Args:
            json_files: List Ä‘Æ°á»ng dáº«n tá»›i JSON files
            token_field: Field chá»©a tokens
        """
        print(f"\nğŸ”¨ Báº®T Äáº¦U XÃ‚Y Dá»°NG INVERTED INDEX Tá»ª JSON FILES")
        print(f"Sá»‘ files: {len(json_files)}")
        print("="*80)
        
        total_docs = 0
        
        for json_file in json_files:
            if not os.path.exists(json_file):
                print(f"âš ï¸ File khÃ´ng tá»“n táº¡i: {json_file}")
                continue
            
            print(f"\nÄang xá»­ lÃ½: {json_file}")
            
            with open(json_file, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            # Náº¿u data lÃ  list
            if isinstance(data, list):
                docs = data
            # Náº¿u data lÃ  dict vá»›i key 'documents' hoáº·c tÆ°Æ¡ng tá»±
            elif isinstance(data, dict):
                docs = data.get('documents', [data])
            else:
                docs = [data]
            
            for doc in tqdm(docs, desc=f"Processing {os.path.basename(json_file)}"):
                try:
                    doc_id = doc.get('doc_id', str(total_docs))
                    tokens = doc.get(token_field, [])
                    
                    if not tokens:
                        tokens = doc.get('tokens', [])
                    
                    if tokens:
                        self.inverted_index.add_document(doc_id, tokens, store_positions=True)
                        total_docs += 1
                        
                except Exception as e:
                    print(f"Lá»—i xá»­ lÃ½ document: {e}")
        
        print(f"\nâœ“ HoÃ n thÃ nh! ÄÃ£ xá»­ lÃ½ {total_docs} documents")
        self.print_statistics()
        
        return True
    
    def save_index_to_mongodb(self, collection_name: str = "inverted_index"):
        """
        LÆ°u inverted index vÃ o MongoDB
        
        Structure:
        - Collection 'inverted_index_terms': LÆ°u index terms
        - Collection 'inverted_index_meta': LÆ°u metadata
        """
        if not self.db:
            if not self.connect_database():
                return False
        
        print(f"\nğŸ’¾ ÄANG LÆ¯U INDEX VÃ€O MONGODB...")
        
        # 1. LÆ°u metadata
        meta_collection = self.db[f"{collection_name}_meta"]
        meta_collection.delete_many({})  # XÃ³a dá»¯ liá»‡u cÅ©
        
        metadata = {
            'created_at': datetime.now(),
            'total_docs': self.inverted_index.total_docs,
            'vocabulary_size': len(self.inverted_index.vocabulary),
            'avg_doc_length': self.inverted_index.avg_doc_length,
            'doc_lengths': self.inverted_index.doc_lengths
        }
        
        meta_collection.insert_one(metadata)
        print(f"âœ“ ÄÃ£ lÆ°u metadata vÃ o {collection_name}_meta")
        
        # 2. LÆ°u index terms (batch insert)
        terms_collection = self.db[f"{collection_name}_terms"]
        terms_collection.delete_many({})  # XÃ³a dá»¯ liá»‡u cÅ©
        
        batch_size = 1000
        batch = []
        
        for term, term_data in tqdm(self.inverted_index.index.items(), desc="Saving terms"):
            batch.append({
                'term': term,
                'df': term_data['df'],
                'postings': term_data['postings']
            })
            
            if len(batch) >= batch_size:
                terms_collection.insert_many(batch)
                batch = []
        
        # Insert remaining
        if batch:
            terms_collection.insert_many(batch)
        
        # Táº¡o index cho term field
        terms_collection.create_index('term', unique=True)
        
        print(f"âœ“ ÄÃ£ lÆ°u {len(self.inverted_index.index)} terms vÃ o {collection_name}_terms")
        print(f"âœ“ ÄÃ£ táº¡o index cho field 'term'")
        
        return True
    
    def save_index_to_json(self, output_dir: str = "outputs", filename: str = None):
        """
        LÆ°u inverted index vÃ o JSON file
        """
        os.makedirs(output_dir, exist_ok=True)
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"inverted_index_{timestamp}.json"
        
        filepath = os.path.join(output_dir, filename)
        
        print(f"\nğŸ’¾ ÄANG LÆ¯U INDEX VÃ€O JSON FILE...")
        
        index_data = self.inverted_index.to_dict()
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(index_data, f, ensure_ascii=False, indent=2)
        
        file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB
        print(f"âœ“ ÄÃ£ lÆ°u index vÃ o: {filepath}")
        print(f"  File size: {file_size:.2f} MB")
        
        return filepath
    
    def save_index_to_pickle(self, output_dir: str = "outputs", filename: str = None):
        """
        LÆ°u inverted index vÃ o Pickle file (nhanh hÆ¡n JSON)
        """
        os.makedirs(output_dir, exist_ok=True)
        
        if not filename:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            filename = f"inverted_index_{timestamp}.pkl"
        
        filepath = os.path.join(output_dir, filename)
        
        print(f"\nğŸ’¾ ÄANG LÆ¯U INDEX VÃ€O PICKLE FILE...")
        
        with open(filepath, 'wb') as f:
            pickle.dump(self.inverted_index, f, protocol=pickle.HIGHEST_PROTOCOL)
        
        file_size = os.path.getsize(filepath) / (1024 * 1024)  # MB
        print(f"âœ“ ÄÃ£ lÆ°u index vÃ o: {filepath}")
        print(f"  File size: {file_size:.2f} MB")
        
        return filepath
    
    @staticmethod
    def load_index_from_json(filepath: str) -> InvertedIndex:
        """Load inverted index tá»« JSON file"""
        print(f"ğŸ“‚ Äang load index tá»«: {filepath}")
        
        with open(filepath, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        inv_index = InvertedIndex.from_dict(data)
        print(f"âœ“ ÄÃ£ load index thÃ nh cÃ´ng!")
        return inv_index
    
    @staticmethod
    def load_index_from_pickle(filepath: str) -> InvertedIndex:
        """Load inverted index tá»« Pickle file"""
        print(f"ğŸ“‚ Äang load index tá»«: {filepath}")
        
        with open(filepath, 'rb') as f:
            inv_index = pickle.load(f)
        
        print(f"âœ“ ÄÃ£ load index thÃ nh cÃ´ng!")
        return inv_index
    
    def print_statistics(self):
        """In thá»‘ng kÃª vá» index"""
        stats = self.inverted_index.get_statistics()
        
        print("\n" + "="*80)
        print("ğŸ“Š THá»NG KÃŠ INVERTED INDEX")
        print("="*80)
        print(f"Total documents: {stats['total_documents']:,}")
        print(f"Vocabulary size: {stats['vocabulary_size']:,}")
        print(f"Average document length: {stats['avg_doc_length']:.1f}")
        print(f"Total postings: {stats['total_postings']:,}")
        print(f"Index size (terms): {stats['index_size_terms']:,}")
        
        # Top 10 terms vá»›i df cao nháº¥t
        top_terms = sorted(
            [(term, data['df']) for term, data in self.inverted_index.index.items()],
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        print(f"\nTop 10 terms (highest document frequency):")
        for term, df in top_terms:
            print(f"  '{term}': {df} documents")


def main():
    """Main function Ä‘á»ƒ demo"""
    print("="*80)
    print("INVERTED INDEX BUILDER")
    print("="*80)
    
    # Khá»Ÿi táº¡o builder
    builder = IndexBuilder()
    
    # Option 1: Build tá»« MongoDB collection (preprocessed data)
    # builder.build_index_from_collection(
    #     collection_name="preprocessed_documents",
    #     token_field="filtered_tokens",
    #     limit=1000
    # )
    
    # Option 2: Build tá»« JSON files
    json_files = [
        "outputs/processed_vnexpress_20241009_123456.json"
    ]
    # builder.build_index_from_json_files(json_files)
    
    # Save index
    # builder.save_index_to_mongodb("inverted_index")
    # builder.save_index_to_json("outputs")
    # builder.save_index_to_pickle("outputs")
    
    print("\nâœ“ HOÃ€N THÃ€NH!")


if __name__ == "__main__":
    main()
